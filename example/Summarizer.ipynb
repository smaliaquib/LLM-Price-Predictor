{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eeb874c-7933-443b-99e1-a12e306c86d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8e5193-0c7f-46ae-9408-840f2aeee72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"}\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe462eec-c187-4af6-9af3-6de93a2e4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are assistant that analyzes contents of website and provide the short summary,\\\n",
    "focus on relevant text and respond in markdown \"\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "def message(website):\n",
    "    return [\n",
    "        {\"role\":\"system\", \"content\": system_prompt},\n",
    "        {\"role\":\"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f155dd40-ae19-4561-813f-00bfc9b81685",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a593029-8a22-4a92-8d93-3a9a9e37d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_api(url='', online=False, model=\"llama3.2\"):\n",
    "    summary = ''\n",
    "    if online:\n",
    "        website = Website(url)\n",
    "        response = openai.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages = message(website)\n",
    "        )\n",
    "        summary = response.choices[0].message.content\n",
    "        \n",
    "    else:\n",
    "        OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "        HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "        website = Website(url)\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": message(website),\n",
    "            \"stream\": False\n",
    "        }\n",
    "        response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "        summary = response.json()['message']['content']\n",
    "\n",
    "    return display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2565a0-37ec-43b3-a352-d6144788a680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary of the Website**\n",
       "=====================================\n",
       "\n",
       "### Introduction\n",
       "\n",
       "The website is owned by Edward Donner, a co-founder and CTO of Nebula.io, a company applying AI to help people discover their potential. The website also features an arena called \"Outsmart\" where LLMs (Large Language Models) compete against each other in a battle of diplomacy and deviousness.\n",
       "\n",
       "### About the Owner\n",
       "\n",
       "Edward Donner is a passionate writer, DJ, and amateur electronic music producer who enjoys experimenting with LLMs. He has co-founded Nebula.io, which uses AI to source, understand, engage, and manage talent.\n",
       "\n",
       "### News and Announcements\n",
       "\n",
       "* **December 21, 2024**: Announcement for the \"LLM Workshop – Hands-on with Agents\" event\n",
       "* **November 13, 2024**: Welcome message for SuperDataScientists, a community of data scientists and AI enthusiasts\n",
       "* **October 16, 2024**: Announcement for resources related to \"Mastering AI and LLM Engineering\"\n",
       "* **January 23, 2025**: Upcoming event \"LLM Workshop – Hands-on with Agents\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_api(url=\"https://edwarddonner.com\", online=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb9e623-3e0b-4234-b5d3-decfb62e4315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Edward Donner's Website\n",
       "\n",
       "Edward Donner's website serves as a personal platform where he shares his passion for coding, LLMs (Large Language Models), and his interests in DJing and music production. He is the co-founder and CTO of Nebula.io, focusing on utilizing AI for talent discovery and management. The site features sections like \"Outsmart,\" which discusses LLM competitions, as well as his professional background, including a previous AI startup that was acquired in 2021.\n",
       "\n",
       "## Recent Announcements\n",
       "- **January 23, 2025**: Introduction of LLM Workshop focusing on hands-on experiences with agents; resources available.\n",
       "- **December 21, 2024**: A welcome note for \"SuperDataScientists.\"\n",
       "- **November 13, 2024**: Release of resources for mastering AI and LLM engineering.\n",
       "- **October 16, 2024**: Resources provided for transitioning from Software Engineer to AI Data Scientist. \n",
       "\n",
       "For further engagement, visitors can connect with him via LinkedIn, Twitter, and Facebook, or subscribe to his newsletter."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_api(url=\"https://edwarddonner.com\", online=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190774c1-e8a9-4072-af65-bcebcd092bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
